{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeab9ab2-5413-486b-83bc-9f3776600083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the environment\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab00844-9120-48ba-b48d-1efc7061dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "\n",
    "file_path = '/Users/nadee/Desktop/PROJECTS/winners-and-losers/config/config.txt'\n",
    "\n",
    "# Open and load the JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# Now `data` is a Python dictionary (or list, depending on the file's structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db294bdb-f2c1-4f39-a08f-8cd6aa38af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the required configuration fields from the file\n",
    "\n",
    "host = config['host']\n",
    "dbname = config['dbName']\n",
    "user = config['user']\n",
    "password = config['password']\n",
    "port = config['port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4136831d-cf7c-4d84-8dcb-4d007d2afc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9v/68m5q1k140v1210s62chp_zr0000gn/T/ipykernel_7363/3555793520.py:101: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  market_summary_df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Define connection parameters\n",
    "conn = psycopg2.connect( \n",
    "    host = host, # pgAdmin 4 > server properties > connection\n",
    "    dbname = dbname, # pgAdmin 4 > database properties\n",
    "    user = user, \n",
    "    password = password,\n",
    "    port = port # pgAdmin 4 > server properties > connection\n",
    ")\n",
    "\n",
    "# Fetch all data from market_summary table in the database\n",
    "query = '''\n",
    "WITH\n",
    "\tSP500_STOCKS_1 AS (\n",
    "\t\tSELECT\n",
    "\t\t\tSP500_TICKER_METADATA.COMPANY_NAME,\n",
    "\t\t\tSP500_TICKER_METADATA.INDUSTRY,\n",
    "\t\t\tMARKET_SUMMARY.*\n",
    "\t\tFROM\n",
    "\t\t\tSP500_TICKER_METADATA\n",
    "\t\t\tRIGHT JOIN MARKET_SUMMARY ON SP500_TICKER_METADATA.TICKER = MARKET_SUMMARY.TICKER\n",
    "\t\tWHERE\n",
    "\t\t\tCOMPANY_NAME IS NOT NULL\n",
    "\t\tORDER BY\n",
    "\t\t\tTIMESTAMP,\n",
    "\t\t\tTICKER\n",
    "\t),\n",
    "\tlagged AS (\n",
    "\t\tSELECT *,\n",
    "\t\t\tLAG(\"close\") OVER (PARTITION BY TICKER ORDER BY TIMESTAMP) AS prev_close\n",
    "\t\tFROM SP500_STOCKS_1\n",
    "\t),\n",
    "\tSP500_STOCKS_2 AS (\n",
    "\t\tSELECT\n",
    "\t\t\t*,\n",
    "\t\t\t(\"close\" - prev_close)/prev_close AS daily_pct_change,\n",
    "\t\t\tAVG(\"close\") OVER (\n",
    "\t\t\t\tPARTITION BY\n",
    "\t\t\t\t\tTICKER\n",
    "\t\t\t\tORDER BY\n",
    "\t\t\t\t\tTIMESTAMP ROWS BETWEEN 2 PRECEDING\n",
    "\t\t\t\t\tAND CURRENT ROW\n",
    "\t\t\t) AS MA03,\n",
    "\t\t\tAVG(\"close\") OVER (\n",
    "\t\t\t\tPARTITION BY\n",
    "\t\t\t\t\tTICKER\n",
    "\t\t\t\tORDER BY\n",
    "\t\t\t\t\tTIMESTAMP ROWS BETWEEN 4 PRECEDING\n",
    "\t\t\t\t\tAND CURRENT ROW\n",
    "\t\t\t) AS MA05,\n",
    "\t\t\tSTDDEV(\"close\") OVER (\n",
    "\t\t\t\tPARTITION BY\n",
    "\t\t\t\t\tTICKER\n",
    "\t\t\t\tORDER BY\n",
    "\t\t\t\t\tTIMESTAMP\n",
    "\t\t\t) AS VOLATILITY,\n",
    "\t\t\tCASE \n",
    "\t\t\t\tWHEN (\n",
    "\t\t\t\t\t(\"close\" - prev_close) > 0\n",
    "\t\t\t\t) THEN 'Advanced'\n",
    "\t\t\t\tELSE 'Declined'\n",
    "\t\t\tEND AS adr_category\n",
    "\t\tFROM\n",
    "\t\t\tlagged\n",
    "\t\tORDER BY\n",
    "\t\t\tTICKER\n",
    "\t),\n",
    "\tvolatility_percentiles AS (\n",
    "\t\tSELECT\n",
    "    \t\tpercentile_cont(0.33) WITHIN GROUP (ORDER BY volatility) AS low_threshold,\n",
    "    \t\tpercentile_cont(0.66) WITHIN GROUP (ORDER BY volatility) AS high_threshold\n",
    "\t\tFROM\n",
    "\tSP500_STOCKS_2\n",
    "\t),\n",
    "\tSP500_STOCKS_3 AS (\n",
    "\t\tSELECT \n",
    "\t\t\tSP500_STOCKS_2.*,\n",
    "\t\t\tCASE \n",
    "\t\t\t\tWHEN SP500_STOCKS_2.volatility IS NULL THEN NULL\n",
    "\t\t\t\tWHEN SP500_STOCKS_2.volatility < volatility_percentiles.low_threshold THEN 'Low'\n",
    "\t\t\t\tWHEN SP500_STOCKS_2.volatility < volatility_percentiles.high_threshold THEN 'Moderate'\n",
    "\t\t\t\tELSE 'High'\n",
    "\t\t\tEND AS volatility_level\n",
    "\t\tFROM SP500_STOCKS_2\n",
    "\t\tCROSS JOIN volatility_percentiles\n",
    "\t)\n",
    "\n",
    "\n",
    "SELECT\n",
    "\tSP500_STOCKS_2.*,\n",
    "\tSP500_STOCKS_3.volatility_level\n",
    "FROM\n",
    "\tSP500_STOCKS_2\n",
    "\tLEFT JOIN SP500_STOCKS_3 \n",
    "\t\tON SP500_STOCKS_2.TIMESTAMP = SP500_STOCKS_3.TIMESTAMP\n",
    "\t\tAND SP500_STOCKS_2.ticker = SP500_STOCKS_3.ticker\n",
    "ORDER BY\n",
    "\tTIMESTAMP, ticker\n",
    "'''\n",
    "\n",
    "# Save the query to dataframe\n",
    "market_summary_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Cleaning up\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8a7fed8-bf9a-4e5c-a6a8-9630b9a309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Google Sheets API \n",
    "\n",
    "SERVICE_ACCOUNT_FILE = '/Users/nadee/Desktop/PROJECTS/winners-and-losers/config/vidhya-etl-dabd5ec76159.json'  # Path to your downloaded JSON file\n",
    "SPREADSHEET_ID = config['SPREADSHEET_ID'] # From the URL between /d/...../edit\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets', \n",
    "          'https://www.googleapis.com/auth/drive']  # Read & write scope\n",
    "RANGE_NAME = 'Sheet1'  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d718ab-a65e-4116-87ea-01b810cc19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes = SCOPES)\n",
    "\n",
    "sheets_service = build('sheets', 'v4', credentials = creds)\n",
    "drive_service  = build('drive', 'v3', credentials = creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425ba1a4-91db-44f6-86d9-ab21429824bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean timestamp columns and drop otc columns\n",
    "\n",
    "market_summary_df['dw_last_updated'] = market_summary_df['dw_last_updated'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "market_summary_df['timestamp'] = market_summary_df['timestamp'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "market_summary_df = market_summary_df.drop(columns = ['otc'])\n",
    "\n",
    "market_summary_df = market_summary_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d714c1e1-960c-4852-866a-e613514b9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to a list of lists\n",
    "\n",
    "values = [market_summary_df.columns.to_list()] + market_summary_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc97ff9-647d-41ab-9e64-524539fae72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to Google Sheet: https://docs.google.com/spreadsheets/d/1hzFGA5F0OI1wDYmrUdkUWTYsYvjsK3RIRurOpD_AY8U\n"
     ]
    }
   ],
   "source": [
    "# Clear the existing data\n",
    "\n",
    "sheets_service.spreadsheets().values().clear(\n",
    "    spreadsheetId = SPREADSHEET_ID,\n",
    "    range = 'Sheet1',\n",
    "    body = {}\n",
    ").execute()\n",
    "\n",
    "# Write the transformed data\n",
    "\n",
    "sheets_service.spreadsheets().values().update(\n",
    "    spreadsheetId = SPREADSHEET_ID,\n",
    "    range = 'Sheet1!A1',\n",
    "    valueInputOption = 'USER_ENTERED',\n",
    "    body={'values': values}\n",
    ").execute()\n",
    "\n",
    "print(f\"Data uploaded to Google Sheet: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
